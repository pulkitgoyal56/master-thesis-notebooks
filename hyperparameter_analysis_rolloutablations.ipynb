{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "\n",
    "from ipywidgets import interact, widgets\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.io import imread, imread_collection\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.transform import AffineTransform, warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"tree_repair_closeness_200_inner3_control0066_nomaxdist/495\"\n",
    "FRAMES = 100\n",
    "\n",
    "BASELINE_IMAGE = '../mbrl/environments/data/white.png'  # '../mbrl/environments/tangram/start.ignore.png'  # None\n",
    "\n",
    "STATIC_JIBBERISH = 'uiih rfvfgbblae ghwyrfyegf'\n",
    "RANDOM_JIBBERISH_LENGTH = 20\n",
    "\n",
    "NEGATIVE_PREFIX = 'Not'\n",
    "STARTING_TEXT_PROMPTS = ['A random image', 'A white canvas']  # 'Geometric shapes on a white background'\n",
    "\n",
    "ALPHA = np.around(np.linspace(0, 0.5, 11), 2)\n",
    "BETA = np.around(np.linspace(0, 0.5, 11), 2)\n",
    "\n",
    "TEMPERATURE = [1, 2, 3, 5, 7, 8, 10, 20, 30, 50]\n",
    "\n",
    "# CATEGORIES = [\"house\", \"bird\", \"fish\", \"tree\", \"cat\", \"dog\", \"horse\", \"rabbit\", \"goat\", \"shirt\", \"chair\"]  # , \"boat\"]\n",
    "CATEGORIES = [\"house\", \"bird\", \"fish\", \"tree\", \"cat\", \"dog\", \"horse\", \"rabbit\", \"goat\", \"shirt\", \"chair\", \"boat\", \"swan\", \"camel\", \"bear\", \"duck\", \"teapot\", \"hammer\", \"boot\", \"key\", \"gun\", \"apple\", \"car\", \"guitar\", \"flower\", \"heart\"]\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIXES = [\n",
    "    [\"\", \"A\", \"An abstract\"],\n",
    "    [\"\", \"A tangram representation of\", \"A tangram puzzle of\", \"A geometric depiction of\", \"A tangram-inspired\", \"A tangram-like\"]\n",
    "]\n",
    "SUFFIXES = [\n",
    "    [\"\", \"made of tangrams\", \"formed from tangrams\", \"consisting of tangrams\", \"assembled from tangrams\", \"created with tangrams\"],\n",
    "    [\"\", \"pattern\", \"configuration\", \"shape\", \"arrangement\", \"composition\"]\n",
    "]\n",
    "NEGATIVE_PREFIXES = [[f\"{NEGATIVE_PREFIX} {prefix[0].lower()}{prefix[1:]}\" if prefix else NEGATIVE_PREFIX for prefix in prefix_list] for prefix_list in PREFIXES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "random.seed(SEED)\n",
    "get_random_string = lambda length: random.choice(string.ascii_lowercase) + ''.join(random.choice(string.ascii_lowercase + ' ' * 2) for _ in range(length - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device=DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('text_embeddings.pt', 'rb') as f:\n",
    "#     text_embeddings = torch.load(f, map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_text_features_list = []\n",
    "negative_text_features_list = []\n",
    "combination_list = []\n",
    "for ps in (post_suffixes := ['', STATIC_JIBBERISH, None, None, None]):\n",
    "    for prefix_list, suffix_list, neg_prefix_list in zip(PREFIXES, SUFFIXES, NEGATIVE_PREFIXES):\n",
    "        for prefix, neg_prefix in zip(prefix_list, neg_prefix_list):\n",
    "            for suffix in suffix_list:\n",
    "                post_suffix = ps if ps is not None else get_random_string(RANDOM_JIBBERISH_LENGTH)\n",
    "                combination_list.append((prefix, f'{neg_prefix}...', suffix, post_suffix))\n",
    "\n",
    "                positive_labels = [f'{prefix} {label} {suffix} {post_suffix}' for label in CATEGORIES]\n",
    "                positive_text_features = model.encode_text(clip.tokenize(positive_labels).to(DEVICE))\n",
    "                positive_text_features /= positive_text_features.norm(dim=-1, keepdim=True)\n",
    "                positive_text_features_list.append(positive_text_features)\n",
    "\n",
    "                negative_labels = [f'{neg_prefix} {label} {suffix} {post_suffix}' for label in CATEGORIES]\n",
    "                negative_text_features = model.encode_text(clip.tokenize(negative_labels).to(DEVICE))\n",
    "                negative_text_features /= negative_text_features.norm(dim=-1, keepdim=True)\n",
    "                negative_text_features_list.append(negative_text_features)\n",
    "\n",
    "positive_text_embeddings = torch.stack(positive_text_features_list)\n",
    "negative_text_embeddings = torch.stack(negative_text_features_list)\n",
    "\n",
    "starting_text_embeddings = []\n",
    "for starting_text_prompt in STARTING_TEXT_PROMPTS:\n",
    "    starting_text_features = model.encode_text(clip.tokenize(starting_text_prompt).to(DEVICE))\n",
    "    starting_text_features /= starting_text_features.norm(dim=-1, keepdim=True)\n",
    "    starting_text_embeddings.append(starting_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_list += [(combination[0], starting_text_prompt) + combination[2:] for starting_text_prompt in STARTING_TEXT_PROMPTS for combination in combination_list]\n",
    "\n",
    "text_embeddings = {}\n",
    "for alpha_text in ALPHA:\n",
    "    text_embeddings[alpha_text] = torch.vstack((\n",
    "            (1 - alpha_text) * positive_text_embeddings - alpha_text * negative_text_embeddings,\n",
    "            *[(1 - alpha_text) * positive_text_embeddings - alpha_text * starting_text_embedding for starting_text_embedding in starting_text_embeddings],\n",
    "    ))\n",
    "    text_embeddings[alpha_text] /= text_embeddings[alpha_text].norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('text_embeddings.pt', 'wb') as f:\n",
    "#     torch.save(text_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {\n",
    "    'normal': [*(pictures := imread_collection(f\"./{FOLDER}/pre-processed*/[!_]*.png\"))][:FRAMES + 1],\n",
    "    'sheared': [img_as_ubyte(warp(picture, AffineTransform(shear=(0.15, 0.15)), cval=1.)) for picture in pictures[:FRAMES + 1]],\n",
    "    'hatched': [*imread_collection(f\"./{FOLDER}/pre-processed*/hatch/[!_]*.png\")][:FRAMES + 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_image_embeddings = dict.fromkeys(images, None)\n",
    "starting_image_embedding = dict.fromkeys(images, None)\n",
    "for image_type in images:\n",
    "    positive_image_embeddings[image_type] = model.encode_image(torch.cat([preprocess(Image.fromarray(image)).to(DEVICE) for image in images[image_type]]).view(-1, 3, 224, 224))\n",
    "    positive_image_embeddings[image_type] /= positive_image_embeddings[image_type].norm(dim=-1, keepdim=True)\n",
    "\n",
    "    starting_image_embedding[image_type] = positive_image_embeddings[image_type][0]\n",
    "    positive_image_embeddings[image_type] = positive_image_embeddings[image_type][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BASELINE_IMAGE is None:\n",
    "    baseline_image_embedding = starting_image_embedding\n",
    "else:\n",
    "    baseline_image_embedding = dict(zip(images.keys(), [\n",
    "        model.encode_image(preprocess(Image.open(BASELINE_IMAGE)).to(DEVICE).unsqueeze(0)).squeeze(0),\n",
    "        model.encode_image(preprocess(Image.fromarray(img_as_ubyte(warp(imread(BASELINE_IMAGE), AffineTransform(shear=(0.15, 0.15)), cval=1.)))).to(DEVICE).unsqueeze(0)).squeeze(0),\n",
    "        model.encode_image(preprocess(Image.open(BASELINE_IMAGE)).to(DEVICE).unsqueeze(0)).squeeze(0)\n",
    "    ]))\n",
    "    for image_type in images:\n",
    "        baseline_image_embedding[image_type] /= baseline_image_embedding[image_type].norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings = dict.fromkeys(images, None)\n",
    "for image_type in images:\n",
    "    image_embeddings[image_type] = {}\n",
    "    for beta_image in BETA:\n",
    "        image_embeddings[image_type][beta_image] = (1 - beta_image) * positive_image_embeddings[image_type] - beta_image * baseline_image_embedding[image_type]\n",
    "        image_embeddings[image_type][beta_image] /= image_embeddings[image_type][beta_image].norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = dict.fromkeys(images, None)\n",
    "for image_type in images:\n",
    "    distances[image_type] = {}\n",
    "    for alpha in ALPHA:\n",
    "        for beta in BETA:\n",
    "            distances[image_type][alpha, beta] = model.logit_scale.exp() * text_embeddings[alpha] @ image_embeddings[image_type][beta].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_entropy = np.log(len(CATEGORIES))\n",
    "\n",
    "results = dict.fromkeys(images, None)\n",
    "entropies = dict.fromkeys(images, None)\n",
    "for image_type in images:\n",
    "    results[image_type] = {}\n",
    "    entropies[image_type] = {}\n",
    "    for temperature in TEMPERATURE:\n",
    "        for alpha in ALPHA:\n",
    "            for beta in BETA:\n",
    "                results[image_type][temperature, alpha, beta] = (distances[image_type][alpha, beta] / temperature).softmax(dim=1)\n",
    "                entropies[image_type][temperature, alpha, beta] = -(results[image_type][temperature, alpha, beta] * torch.log(results[image_type][temperature, alpha, beta])).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# def update_heatmap(alpha, beta, image_type, prompt_set):\n",
    "#     for temperature in TEMPERATURE:\n",
    "#         plt.plot(entropies[image_type][temperature, alpha, beta][prompt_set].cpu(), label=temperature)\n",
    "#     plt.ylim(0, max_entropy)\n",
    "#     plt.ylabel('Entropy')\n",
    "#     plt.xlabel('Rollout')\n",
    "#     plt.title(combination_list[prompt_set])\n",
    "#     # plt.legend(title='Temperature')\n",
    "\n",
    "# interact(update_heatmap,\n",
    "#          alpha=widgets.SelectionSlider(options=ALPHA),\n",
    "#          beta=widgets.SelectionSlider(options=BETA),\n",
    "#          image_type=widgets.RadioButtons(options=images.keys()),\n",
    "#          prompt_set=widgets.SelectionSlider(value=117, options=range(len(combination_list))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = pd.DataFrame(combination_list, columns=['Prefix', 'Negative prefix', 'Suffix', 'Post suffix'])\n",
    "counts_per_combination = {combination:combination_list.count(combination) for combination in combination_list}\n",
    "combination_list_unique = list(counts_per_combination.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_combination = combination_list_unique[(best_combination_index := 343)]\n",
    "# best_combination_prefix, best_combination_neg_prefix, best_combination_suffix, best_combination_post_suffix = best_combination\n",
    "# best_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinations[(combinations['Prefix'] == best_combination_prefix) & (combinations['Suffix'] == best_combination_suffix)].iloc[3::5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Across jibberish for a negative prefix\n",
    "- Across negative prefixes for a jibberish\n",
    "- Across image operations\n",
    "- With and without texturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_costs = np.load(f\"./{FOLDER}/closeness_results_{len(pictures) - 1}.npy\")[1:FRAMES + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2625147/4173716448.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('rainbow', 2 * len(combination_list))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5f28a7e9aa4390bd700eb780b86d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='alpha_text', index=10, options=(0.0, 0.05, 0.1, 0.15, 0.2, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "cmap = plt.cm.get_cmap('rainbow', 2 * len(combination_list))\n",
    "def plot(alpha_text, beta_image, temperature, prefix, suffix, jibberish, negative_prompt_style, image_type, moving_average=0):\n",
    "    jibberish = ['None', f'Same ({STATIC_JIBBERISH})', *[f'Random #{i}' for i in range(1, len(post_suffixes) - 1)]].index(jibberish)\n",
    "    negative_prompt_style = ([f'{NEGATIVE_PREFIX}...'] + STARTING_TEXT_PROMPTS).index(negative_prompt_style)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 5), sharex=True, sharey=True)\n",
    "    axs[0].set_ylim(0, max_entropy)\n",
    "\n",
    "    fig.supylabel('Entropy', x=0.005)\n",
    "    fig.supxlabel('Rollout', x=0.515)\n",
    "    for ax in axs.ravel():\n",
    "        ax.plot(closeness_costs, c='k')  # label='Closeness Costs'\n",
    "\n",
    "    if moving_average:\n",
    "        shift = int(np.floor(moving_average // 2))\n",
    "        x = np.arange(len(closeness_costs))[(shift := moving_average // 2):-shift + (moving_average + 1) % 2 if moving_average > 2 else None]\n",
    "\n",
    "    prompt_sets = combinations[(combinations['Prefix'] == prefix) & (combinations['Suffix'] == suffix)]\n",
    "    jibberish = prompt_sets['Post suffix'].unique()[jibberish]\n",
    "    negative_prompt_style = prompt_sets['Negative prefix'].unique()[negative_prompt_style]\n",
    "\n",
    "    prompt_indices_jibberish = prompt_sets.loc[combinations['Negative prefix'] == negative_prompt_style].index.to_list()\n",
    "    prompt_indices_negativep = prompt_sets.loc[combinations['Post suffix'] == jibberish].index.to_list()\n",
    "\n",
    "    for i in prompt_indices_jibberish:\n",
    "        data = entropies[image_type][temperature, alpha_text, beta_image][i].cpu()\n",
    "        axs[0].plot(data, alpha=0.1, c=cmap(i), label='<Empty>' if not combinations['Post suffix'].loc[i] else '<Random>')\n",
    "        if moving_average:\n",
    "            axs[0].plot(x, np.convolve(data, np.ones(moving_average) / moving_average, mode='valid'), c=cmap(i), label='<Empty>' if not combinations['Post suffix'].loc[i] else '<Random>')\n",
    "    axs[0].legend(*(lambda x: (x.values(), x.keys()))(dict(zip(*axs[0].get_legend_handles_labels()[::-1]))), title='Post suffix', loc=4)\n",
    "    axs[0].set_title('Effect of Post Suffix')\n",
    "\n",
    "    for i in prompt_indices_negativep:\n",
    "        data = entropies[image_type][temperature, alpha_text, beta_image][i].cpu()\n",
    "        axs[1].plot(data, alpha=0.1, c=cmap(i), label=combinations['Negative prefix'].loc[i])\n",
    "        if moving_average:\n",
    "            axs[1].plot(x, np.convolve(data, np.ones(moving_average) / moving_average, mode='valid'), c=cmap(i), label=combinations['Negative prefix'].loc[i])\n",
    "    axs[1].legend(*(lambda x: (x.values(), x.keys()))(dict(zip(*axs[1].get_legend_handles_labels()[::-1]))), title='Negative Embedding', loc=4)\n",
    "    axs[1].set_title('Effect of Negative Embedding')\n",
    "\n",
    "    prompt_indices_operations = prompt_sets.loc[(combinations['Negative prefix'] == negative_prompt_style) & (combinations['Post suffix'] == jibberish)].index.to_list()[0]\n",
    "    for i, i_ in enumerate(images):\n",
    "        data = entropies[i_][temperature, alpha_text, beta_image][prompt_indices_operations].cpu()\n",
    "        axs[2].plot(data, alpha=0.1, c=cmap(i), label=i_)\n",
    "        if moving_average:\n",
    "            axs[2].plot(x, np.convolve(data, np.ones(moving_average) / moving_average, mode='valid'), c=cmap(i * len(combination_list)), label=i_)\n",
    "    axs[2].legend(*(lambda x: (x.values(), x.keys()))(dict(zip(*axs[2].get_legend_handles_labels()[::-1]))), title='Operation', loc=4)\n",
    "    axs[2].set_title('Effect of Image Operations')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "interact(plot,\n",
    "         alpha_text=widgets.SelectionSlider(value=0.5, options=ALPHA),\n",
    "         beta_image=widgets.SelectionSlider(value=0., options=BETA),\n",
    "         temperature=widgets.SelectionSlider(value=3, options=TEMPERATURE),\n",
    "        #  prompt_set=widgets.SelectionSlider(value=best_combination_index, options=range(len(counts_per_combination)))\n",
    "         prefix=widgets.Dropdown(options=sum(PREFIXES, [])),\n",
    "         suffix=widgets.Dropdown(options=sum(SUFFIXES, [])),\n",
    "         jibberish=widgets.RadioButtons(options=['None', f'Same ({STATIC_JIBBERISH})', *[f'Random #{i}' for i in range(1, len(post_suffixes) - 1)]]),\n",
    "         negative_prompt_style=widgets.RadioButtons(options=[f'{NEGATIVE_PREFIX}...', *STARTING_TEXT_PROMPTS]),\n",
    "         image_type=widgets.RadioButtons(options=images.keys()),\n",
    "         moving_average=widgets.IntSlider(value=1, min=1, max=30, step=1, continuous_update=False)\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbrl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
